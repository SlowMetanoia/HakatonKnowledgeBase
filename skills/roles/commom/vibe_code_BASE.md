## Краткий пересказ гайда.
https://habr.com/ru/articles/986930/

## Общее понимание

https://www.latent.space/p/ai-engineer

https://www.deeplearning.ai/the-batch/

## Vibe-coding и практика

https://karpathy.ai/lexicon/v.html

https://www.builder.io/blog/ai-first-development

## Copilot / IDE-подход

https://docs.github.com/en/copilot

https://cursor.sh/blog

## Про промпты (на будущее)

https://www.promptingguide.ai/

https://www.anthropic.com/index/prompting-guide

Этот документ рискует быть большим, поэтому я буду делать его описавая свои шаги. Условно говоря, я буду писать не столько мануал, сколько конспект того, что прочитал. 
Примерно так-же пишутся статьи на хабр.
## Несчастные попытки в Cursor

## Self-hosted
Для начала надо понять, можно ли тестить штуки локально. Так что первым делом поставил LMStudio
На сколько я понимаю, оно есть подо все современные операционки.

Поставил Mixtral 8x7B Instruct GGUF оно ставится прямо из UI в LMStudio
Я брал эту:
```
tensorblock/Mixtral-8x7B-Instruct-v0.1-GGUF
```
В целом, для тетов подойдёт что угодно, главное чтобы был openAI-like endpoint 

Не то, чтобы я знал, что ставлю. Это мне посоветовал chat-gpt
Я взял 4-битную квантификацию.
В целом, видеокарта в современном домашнем компе может такое потянуть.

## Cursor или интеграции?
Если коротко, то курсор отличается от всех прочих тем, что это именно AI-first IDE. Он точился именно под это. Задумка курсора в том, чтобы быть AI разработчиком которому ты
ставишь задачи. А любая интеграция - это именно что AI-инструмент для разработчика. Соотвественно, использоваться они могут и/или должны довольно сильно по-разному.

## Дружим Cursor с локальной нейронкой
Следующим шагом пробуем заставить курсор работать с локльной моделью.
Ладно, да. На этом этапе пришлось заплатить мзду. Теоретически можно заставить Cursor работать с локальной моделью и без этого, но я пытался типа... пару часов
И у меня не особо получилось по итогу, но после оплаты 20 кажется долларов, собака, он всё равно не завёлся. Почему? Потому что пошёл я нафиг - вот почему!
Если коротко, курсор очень хочет чтобы ты платил денег и поэтому запрещает ходить по локальным IP. Какая дичь. Решение есть. Выглядит вот так:
(Ну, для меня выглядело так)
(Не надо этого делать, пока док не прочитан целиком.)
```bash
brew install ngrok
ngrok config add-authtoken <токен выдают при регистрации на ngrok.com>
ngrok http <порт на котором крутится модель>
```

Получаем что-то типа
https://concussive-swelteringly-gabriella.ngrok-free.dev
ставим это в cursor settings -> models -> API -> Override OpenAI base URL и добавляем в конец "/v1"
И... Всё падает, потому что не хватает контекста.
Для понимания, я открыл проект в котором 1 файл с кодом на 200 строк, а он захотел типа 15k токенов. В этот момент у меня возникли некоторые подозрения по поводу... целесообразности.
Впрочем, видеопамяти у меня много, так что поднимаем контекст и продолжаем.

В итоге получилось заставить курсор работать с локальной моделью, однако ограничений - тонна!
В целом, после этого курсор не будет отличаться от всех остальных интеграций с чем угодно. Например с тем-же копилотом.
В остальном cursor - это форк vscode со всеми его плюсами и минусами.

Резюме.
Говорят, курсор - мощный. Говорят.
Но вот использование его как платформы для полностью self-hosted решений - не получится. В целом, курсор этому даже скорее противодействует. Он хочет ваших денег за подписку и потом ещё, если вы кодите много. Насколько его использование оправданно - вопрос открытый. Скорее всего да, для каких-то задач. Для каких - надо разбираться, что я постараюсь сделать в дальнейшем.

### Резюме по использованию Cursor.
Быстро. Относительно качественно. 
Способно само фиксить баги. 
Может самостоятельно писать как документы, так и код.
Может работать с многими файлами. Доставточно неплохо ревьюит код, если сказать, что именно искать.
Если объяснить плохо - напишет как придётся. Легко нарушает архитектуру, если за этим не следить.

Самое неприятное - это тот факт, что у меня за 3 дня активной работы закончились тоекны. В целом, есть всякие оптимизаторы и надо понимать, что я тоже не особо жался на запросы и агентов: использовал топ модели, где в целом можно было обойтись без них и т.п.

Уровень того что сделано за 3 дня: 
- Проект прерписан под новую архитктуру
- Добавлены сложные конфиги(JSON, DSL)
- Написаны штук 10 новых фич
- Добавлена персистентность
- Добавлена регистрация

В строчках кода там где-то 4000-4500

По итогу ощущения скорее хорошие, чем нет. Код в среднем пишет достаточно идиоматичный, хотя бывают заскоки: он мне в функциональном приложении написал классичкский ООП-билдер(да, с состоянием).
Пользоваться для тяжеловесного рефакторинга можно, но нужен некоторый скилл в промптах. И без понимания он тебе ничего не даст - ты ему просто объяснить не сможешь, если не понмаешь, как оно должно быть.

## Агенты
Окей. Следующий Опыт, который я решил попробовать - это claude code агенты.
Я пользовался вот этой статьёй.
https://habr.com/ru/articles/984160/

## Краткий гайд, что делать
Во-первых, спецификация.
Перед тем, как писать код всегда нужно просить написать документ, а также просить ИИ задавать вопросы, пока не получится чётких требований.
Но на этом этапе мы только описываем "чего хотим" - спеки для последующих этапов. В целом, делать это можно при помощи любой модели откуда угодно. Chat-gpt 5.2 thinking подойдёт.

Далее пихаем получившийся спек в тот-же 5.2 thinking и просим написать план. На прошлом этапе мы задали направление. На этом - определяем крупные шаги.

Затем, разбиваем крупные задачи на маленькие тикеты - законченные изменения, которые можно тестировать и коммитить отдельно.

В идеале - подключить для модели доки. Можно через MCP.

Правила для модели. Условно говоря, архитектурный документ, код-стайл, линтеры, запреты/ограничения. Иначе модель превращается в злорадного джуна, который знает как надо, но где-то делает, а где-то нет.

Тесты и контроль. По понятным причинам, код вышедший из-под пера ИИ - это экспериментальный код. Это надо понимать и его обязательно надо обкладывать тестами.
Для чего надо добавлять к тикетам ещё и план тестирования. Т.е. при разбивке на тикеты обязательно заставить модель написать спеку на тесты, которые позволят проверить работоспособность решения.

Коммиты. Сделал тикет - проверь и сделай коммит. Это save-point на случай, если что-то пошло не так.

Правда в том, что все этапы до разбиения на тикеты - ускоряют и стабилизируют разработку. Уменьшают используемые токены, таким образом.
А вот тикеты - да, ещё сильнее стабилизируют, но скорее негативно сказываются на токенах. Впрочем, конечно, чем больше проект, тем больший смысл это имеет.

Резюме.
Если коротко, то нормально делай- нормально будет. Модель - не волшебная палочка, а инструмент со своими ограничениями и пользоваться ей надо чётко понимая, что она умеет, а что нет.


